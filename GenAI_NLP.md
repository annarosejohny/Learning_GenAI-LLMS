## Generative AI for NLP

- **Evolution**
![Evolution](https://github.com/user-attachments/assets/f6063532-b288-4db6-b2b7-147f31cc43c5)
- **Advancemements**
  - Machine translation
    - enables precise and contex-aware conversions
  - Chatbot converstaions
    - makes conversations natural and human-like
  - Sentimental analysis
    - grasps subtle language expressions
  - Test summarizations
    - recognizes core meaning and significance of text
- **LLMs**
  - Uses AI and deep learning with cast datasets
  - Involves training datasets running into petabytes
  - Contains billions of paramters, which are fine-tuned based on the use case
  - **Training**
    - Understanding language structures and contexts
    - Capturing of human language
    - Faciliating more natural interactions
    - Predicting next word in a sequence
    - Producing creative content with minimal task-specific training
  - Examples
    - GPT - Acts as decoder. Adept at generating text. Used in chatbots
    - BERT - Utilizes encoder-only transformer architecture. Understands the context of a word in a sentence. Used in sentimental analysis and question answering.
    - BART and T5 - Use encoder-decoder architecture. Versatile for various NLP tasks. 
- GPT vs ChatGPT
  ![GPT_ChatGPT](https://github.com/user-attachments/assets/ff6956ad-5357-448a-b76a-7e3ed73accde)

  
